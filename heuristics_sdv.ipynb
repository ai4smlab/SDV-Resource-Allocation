{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8220c4ca",
   "metadata": {},
   "source": [
    "# Heuristics-based Resource Allocation in Software-defined Vehicles\n",
    "\n",
    "This notebook implements three heuristic algorithms for allocating applications to virtual machines (VMs) in Software-Defined Vehicles (SDVs).  \n",
    "It enforces ISO 26262 safety rules, dependency, and conflict constraints, while targeting scalability to up to 800 applications.  \n",
    "\n",
    "We implement and evaluate:\n",
    "- **CSCH** (Constraint-Satisfying Constructive Heuristic)  \n",
    "- **CSCH-Guided** (Degree-aware variant of CSCH)  \n",
    "- **Adaptive GA (light)** (multi-start randomized heuristic)  \n",
    "\n",
    "Each method is benchmarked against exact ILP solvers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be290245",
   "metadata": {},
   "source": [
    "## 1. Setup and Global Parameters\n",
    "We define the SDV platform constants and paths to the benchmark datasets.  \n",
    "These parameters enforce per-VM and platform-wide limits using ADLINK’s in-vehicle platform as hardware\n",
    "reference and defined a target platform with 80 cores and\n",
    "768 GB RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6847c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# ---- Platform constants ----\n",
    "APP_CORE = 0.05\n",
    "APP_MEM  = 50.0\n",
    "VM_CORE  = 1.0\n",
    "VM_MEM   = 96000.0\n",
    "MAX_CORE = 80.0\n",
    "MAX_MEM  = 768000.0\n",
    "MAX_APPS_PER_VM = int(VM_CORE / APP_CORE)  # 20 apps/VM\n",
    "VM_CAP = 80\n",
    "\n",
    "# ---- Dataset path ----\n",
    "BASE_DIR = \"itsc_2022_project/itsc-2022-master-Py-project/Py/project\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a231",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Each dataset folder (`data_{n}_{i}`) contains:\n",
    "- `app_safe.csv`: binary vector (1 = safety-critical, 0 = non-safety)\n",
    "- `app_dep.csv`: dependency matrix\n",
    "- `app_conf.csv`: conflict matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28754787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scenario(folder):\n",
    "    safe = pd.read_csv(os.path.join(folder, \"app_safe.csv\"), header=None).values.flatten().astype(int)\n",
    "    dep  = pd.read_csv(os.path.join(folder, \"app_dep.csv\"),  header=None).values.astype(int)\n",
    "    conf = pd.read_csv(os.path.join(folder, \"app_conf.csv\"), header=None).values.astype(int)\n",
    "    return safe, dep, conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4f0cf",
   "metadata": {},
   "source": [
    "## 3. Helper Functions\n",
    "We define:\n",
    "- **Dependency components**: group applications connected by dependency edges.\n",
    "- **Greedy coloring**: avoid conflicts by assigning apps to non-overlapping colors.\n",
    "- **Bin packing**: ensure each VM does not exceed 20 apps (1 core, 96GB).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35591427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def components_from_dep(dep):\n",
    "    n = dep.shape[0]\n",
    "    adj = [[] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if dep[i][j]==1 or dep[j][i]==1:\n",
    "                adj[i].append(j); adj[j].append(i)\n",
    "    comp_id = [-1]*n\n",
    "    comps = []\n",
    "    for i in range(n):\n",
    "        if comp_id[i] != -1: continue\n",
    "        q = deque([i]); comp_id[i] = len(comps); cur=[i]\n",
    "        while q:\n",
    "            u=q.popleft()\n",
    "            for v in adj[u]:\n",
    "                if comp_id[v]==-1:\n",
    "                    comp_id[v]=comp_id[i]; q.append(v); cur.append(v)\n",
    "        comps.append(cur)\n",
    "    return comps\n",
    "\n",
    "def greedy_color_with_order(nodes, conf, order=None):\n",
    "    \"\"\"Greedy coloring on the conflict graph restricted to `nodes`.\"\"\"\n",
    "    if not nodes: return []\n",
    "    if order is None:\n",
    "        seq = nodes[:]\n",
    "    else:\n",
    "        rank = {a:i for i,a in enumerate(order)}\n",
    "        seq = sorted(nodes, key=lambda a: rank.get(a, 10**9))\n",
    "    colors = []\n",
    "    for a in seq:\n",
    "        placed = False\n",
    "        for col in colors:\n",
    "            if all(conf[a][b]==0 and conf[b][a]==0 for b in col):\n",
    "                col.append(a); placed=True; break\n",
    "        if not placed:\n",
    "            colors.append([a])\n",
    "    return colors\n",
    "\n",
    "def bin_by_capacity(app_list):\n",
    "    \"\"\"Split a color class into VM-sized bins (≤ 20 apps per VM).\"\"\"\n",
    "    bins = []\n",
    "    cur = []\n",
    "    for a in app_list:\n",
    "        cur.append(a)\n",
    "        if len(cur)==MAX_APPS_PER_VM:\n",
    "            bins.append(cur); cur=[]\n",
    "    if cur: bins.append(cur)\n",
    "    return bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d093c1d",
   "metadata": {},
   "source": [
    "## 4. Core Builder\n",
    "This function strictly enforces:\n",
    "- Per-VM capacity (1 core, 96GB, max 20 apps)\n",
    "- Safety-critical replication (2 replicas on distinct VMs)\n",
    "- FFI isolation (no mixed safety levels)\n",
    "- Conflicts and dependency co-location\n",
    "- Platform caps (80 VMs, 80 cores, 768GB)\n",
    "\n",
    "It serves as the backend for all four heuristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622cc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feasible_capped(safe, dep, conf, order_hint_safe=None, order_hint_non=None):\n",
    "    n = len(safe)\n",
    "    comps = components_from_dep(dep)\n",
    "    total_placements = 0\n",
    "    vms = 0\n",
    "\n",
    "    for cid, C in enumerate(comps):\n",
    "        has_safe = any(safe[a]==1 for a in C)\n",
    "        C_safe   = [a for a in C if safe[a]==1]\n",
    "        C_non    = [a for a in C if safe[a]==0]\n",
    "\n",
    "        ohs = None if order_hint_safe is None else order_hint_safe.get(cid)\n",
    "        ohn = None if order_hint_non  is None else order_hint_non.get(cid)\n",
    "\n",
    "        safe_cols = greedy_color_with_order(C_safe, conf, order=ohs)\n",
    "        non_cols  = greedy_color_with_order(C_non,  conf, order=ohn)\n",
    "\n",
    "        safe_bins = [bin_by_capacity(col) for col in safe_cols]\n",
    "        non_bins  = [bin_by_capacity(col) for col in non_cols]\n",
    "\n",
    "        R = 2 if has_safe else 1\n",
    "        for _ in range(R):\n",
    "            # safety VMs\n",
    "            for bins in safe_bins:\n",
    "                for b in bins:\n",
    "                    vms += 1\n",
    "                    if vms > VM_CAP:\n",
    "                        return False, vms, None, None, \"vm_cap_exceeded\"\n",
    "                    total_placements += len(b)\n",
    "            # non-safety VMs\n",
    "            for bins in non_bins:\n",
    "                for b in bins:\n",
    "                    vms += 1\n",
    "                    if vms > VM_CAP:\n",
    "                        return False, vms, None, None, \"vm_cap_exceeded\"\n",
    "                    total_placements += len(b)\n",
    "\n",
    "    core_used = total_placements * APP_CORE\n",
    "    mem_used  = total_placements * APP_MEM\n",
    "    if core_used > MAX_CORE + 1e-9:\n",
    "        return False, vms, core_used, mem_used, \"platform_totals_core\"\n",
    "    if mem_used  > MAX_MEM + 1e-6:\n",
    "        return False, vms, core_used, mem_used, \"platform_totals_mem\"\n",
    "    return True, vms, core_used, mem_used, \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ddb47",
   "metadata": {},
   "source": [
    "## 5. We report (per apps): Variables and Constraints counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ee10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ilp_counts_for_dataset(safe, dep, conf, V_cap=VM_CAP):\n",
    "    n = len(safe)\n",
    "    V = V_cap\n",
    "    # Matches linear scaling in the original paper.\n",
    "    variables = n * V + 320\n",
    "\n",
    "    n_safe  = int(safe.sum())\n",
    "    n_nsafe = n - n_safe\n",
    "    dep_pairs  = int(dep.sum())  - int(np.trace(dep))\n",
    "    conf_pairs = int(conf.sum()) - int(np.trace(conf))\n",
    "\n",
    "    constraints = (\n",
    "        1                # balance/objective helpers\n",
    "        + V              # VM enable\n",
    "        + V              # capacity helpers\n",
    "        + n              # app placed\n",
    "        + n_nsafe * V    # non-safety app-to-VM\n",
    "        + n_safe  * V    # safety app-to-VM (slot 1), slot 2 implied via slot replication\n",
    "        + dep_pairs * V  # dependency constraints\n",
    "        + conf_pairs * V # conflict constraints\n",
    "    )\n",
    "    return variables, constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5b555",
   "metadata": {},
   "source": [
    "## 6. Three heuristic methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc652a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_csch(folder):\n",
    "    safe, dep, conf = load_scenario(folder)\n",
    "    t0=time.time()\n",
    "    ok, vms, core, mem, reason = build_feasible_capped(safe, dep, conf, None, None)\n",
    "    vars_cnt, cons_cnt = ilp_counts_for_dataset(safe, dep, conf)\n",
    "    return {\"method\":\"CSCH\",\"apps\":len(safe),\"vms\":vms,\"feasible\":ok,\"reason\":reason,\n",
    "            \"core_used\":core,\"mem_used\":mem,\"time_s\":time.time()-t0,\n",
    "            \"Variables\":vars_cnt,\"Constraints\":cons_cnt}\n",
    "\n",
    "def run_csch_guided(folder):\n",
    "    safe, dep, conf = load_scenario(folder)\n",
    "    comps = components_from_dep(dep)\n",
    "    deg = np.array(dep.sum(axis=1) + conf.sum(axis=1))\n",
    "    order_hint_safe = {}\n",
    "    order_hint_non  = {}\n",
    "    for cid, C in enumerate(comps):\n",
    "        Cs = [a for a in C if safe[a]==1]\n",
    "        Cn = [a for a in C if safe[a]==0]\n",
    "        if Cs: order_hint_safe[cid] = list(sorted(Cs, key=lambda a: -deg[a]))\n",
    "        if Cn: order_hint_non[cid]  = list(sorted(Cn, key=lambda a: -deg[a]))\n",
    "    t0=time.time()\n",
    "    ok, vms, core, mem, reason = build_feasible_capped(safe, dep, conf, order_hint_safe, order_hint_non)\n",
    "    vars_cnt, cons_cnt = ilp_counts_for_dataset(safe, dep, conf)\n",
    "    return {\"method\":\"CSCH-Guided\",\"apps\":len(safe),\"vms\":vms,\"feasible\":ok,\"reason\":reason,\n",
    "            \"core_used\":core,\"mem_used\":mem,\"time_s\":time.time()-t0,\n",
    "            \"Variables\":vars_cnt,\"Constraints\":cons_cnt}\n",
    "\n",
    "def run_adaptive_ga_light(folder, restarts=16, seed=0):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    safe, dep, conf = load_scenario(folder)\n",
    "    comps = components_from_dep(dep)\n",
    "\n",
    "    best = None\n",
    "    t0 = time.time()\n",
    "    for _ in range(restarts):\n",
    "        ohs, ohn = {}, {}\n",
    "        for cid, C in enumerate(comps):\n",
    "            Cs = [a for a in C if safe[a]==1]\n",
    "            Cn = [a for a in C if safe[a]==0]\n",
    "            if Cs: tmp = Cs[:]; random.shuffle(tmp); ohs[cid]=tmp\n",
    "            if Cn: tmp = Cn[:]; random.shuffle(tmp); ohn[cid]=tmp\n",
    "        ok, vms, core, mem, reason = build_feasible_capped(safe, dep, conf, ohs, ohn)\n",
    "        if ok and (best is None or vms < best[\"vms\"]):\n",
    "            best = {\"vms\":vms,\"core\":core,\"mem\":mem}\n",
    "    t_elapsed = time.time()-t0\n",
    "    vars_cnt, cons_cnt = ilp_counts_for_dataset(safe, dep, conf)\n",
    "    if best is None:\n",
    "        return {\"method\":\"Adaptive-GA (light)\",\"apps\":len(safe),\"vms\":None,\"feasible\":False,\"reason\":\"vm_cap_exceeded\",\n",
    "                \"core_used\":None,\"mem_used\":None,\"time_s\":t_elapsed,\n",
    "                \"Variables\":vars_cnt,\"Constraints\":cons_cnt}\n",
    "    return {\"method\":\"Adaptive-GA (light)\",\"apps\":len(safe),\"vms\":best[\"vms\"],\"feasible\":True,\"reason\":\"\",\n",
    "            \"core_used\":best[\"core\"],\"mem_used\":best[\"mem\"],\"time_s\":t_elapsed,\n",
    "            \"Variables\":vars_cnt,\"Constraints\":cons_cnt}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92422f8",
   "metadata": {},
   "source": [
    "## 7. Results Summary\n",
    "Aggregate results across three datasets per size.  \n",
    "Compute:\n",
    "- Average VMs\n",
    "- Average runtime ± std\n",
    "- Average cores used\n",
    "- Variables/constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "938efa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_methods_capped(size):\n",
    "    rows=[]\n",
    "    for d in (1,2,3):\n",
    "        folder = os.path.join(BASE_DIR, f\"data_{size}_{d}\")\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"⚠️ Missing {folder}\")\n",
    "            continue\n",
    "        for fn in (run_csch, run_csch_guided, run_adaptive_ga_light):\n",
    "            r = fn(folder)\n",
    "            r[\"dataset\"] = f\"data_{size}_{d}\"\n",
    "            rows.append(r)\n",
    "            print(f\"{'✅' if r['feasible'] else '❌'} {r['dataset']} | {r['method']} | VMs={r['vms']} | Vars={r['Variables']} | Cons={r['Constraints']} | {r['time_s']:.3f}s\")\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0e31b",
   "metadata": {},
   "source": [
    "## 8. Summary (means, time (s), stds, cores, variables and constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1a81eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_runs(df, tag):\n",
    "    # per apps × method\n",
    "    agg = (df.groupby([\"apps\",\"method\"], as_index=False)\n",
    "             .agg(VMs_Mean=(\"vms\",\"mean\"),\n",
    "                  VMs_Std=(\"vms\",\"std\"),\n",
    "                  Time_Mean=(\"time_s\",\"mean\"),\n",
    "                  Time_Std=(\"time_s\",\"std\"),\n",
    "                  Cores_Mean=(\"core_used\",\"mean\")))\n",
    "    for c in [\"VMs_Mean\",\"VMs_Std\",\"Time_Mean\",\"Time_Std\",\"Cores_Mean\"]:\n",
    "        agg[c] = agg[c].astype(float).round(6)\n",
    "\n",
    "    print(f\"\\n=== {tag}: LONG FORMAT (per apps × method) ===\")\n",
    "    print(agg.sort_values([\"apps\",\"method\"]).to_string(index=False))\n",
    "\n",
    "    vm_wide   = agg.pivot(index=\"apps\", columns=\"method\", values=\"VMs_Mean\").sort_index()\n",
    "    tmu_wide  = agg.pivot(index=\"apps\", columns=\"method\", values=\"Time_Mean\").sort_index()\n",
    "    tsd_wide  = agg.pivot(index=\"apps\", columns=\"method\", values=\"Time_Std\").sort_index()\n",
    "    core_wide = agg.pivot(index=\"apps\", columns=\"method\", values=\"Cores_Mean\").sort_index()\n",
    "\n",
    "    both = tmu_wide.copy().astype(object)\n",
    "    for a in both.index:\n",
    "        for m in both.columns:\n",
    "            both.loc[a, m] = f\"{tmu_wide.loc[a,m]:.3f} ± {tsd_wide.loc[a,m]:.3f}\"\n",
    "\n",
    "    print(f\"\\n=== {tag}: WIDE — Average VMs (methods as columns) ===\")\n",
    "    print(vm_wide.round(6).to_string())\n",
    "\n",
    "    print(f\"\\n=== {tag}: WIDE — Runtime (s, mean ± std) ===\")\n",
    "    print(both.to_string())\n",
    "\n",
    "    print(f\"\\n=== {tag}: WIDE — Average Cores Used (methods as columns) ===\")\n",
    "    print(core_wide.round(6).to_string())\n",
    "\n",
    "    # Problem scale (apps-averaged across datasets/methods)\n",
    "    scale = (df.groupby(\"apps\", as_index=False)\n",
    "               .agg(Variables=(\"Variables\",\"mean\"),\n",
    "                    Constraints=(\"Constraints\",\"mean\")))\n",
    "    scale[\"Variables\"]   = scale[\"Variables\"].round(0).astype(int)\n",
    "    scale[\"Constraints\"] = scale[\"Constraints\"].round(0).astype(int)\n",
    "    print(f\"\\n=== {tag}: Table-II style — Problem scale (averaged over datasets) ===\")\n",
    "    print(scale.to_string(index=False))\n",
    "\n",
    "    # minimal solutions (min VMs per dataset → average over 3 datasets)\n",
    "    def min_vm_per_group(g):\n",
    "        min_v = g[\"vms\"].min()\n",
    "        cores_at_min = g.loc[g[\"vms\"]==min_v, \"core_used\"].mean()\n",
    "        return pd.Series({\"VMs_Min\": float(min_v), \"Cores_at_Min\": float(cores_at_min)})\n",
    "    per_ds = df.groupby([\"apps\",\"dataset\"]).apply(min_vm_per_group).reset_index()\n",
    "    table2 = (per_ds.groupby(\"apps\", as_index=False)\n",
    "                    .agg(VMs=(\"VMs_Min\",\"mean\"),\n",
    "                         Cores=(\"Cores_at_Min\",\"mean\")))\n",
    "    table2[\"VMs\"]   = table2[\"VMs\"].round(2)\n",
    "    table2[\"Cores\"] = table2[\"Cores\"].round(2)\n",
    "    print(f\"\\n=== {tag}: Minimal solutions (avg over data_{{i=1..3}}) ===\")\n",
    "    print(table2.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e6b35",
   "metadata": {},
   "source": [
    "## 9. Example run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d759b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data_100_1 | CSCH | VMs=21 | Vars=8320 | Cons=139461 | 0.006s\n",
      "✅ data_100_1 | CSCH-Guided | VMs=21 | Vars=8320 | Cons=139461 | 0.006s\n",
      "✅ data_100_1 | Adaptive-GA (light) | VMs=21 | Vars=8320 | Cons=139461 | 0.099s\n",
      "✅ data_100_2 | CSCH | VMs=18 | Vars=8320 | Cons=148581 | 0.009s\n",
      "✅ data_100_2 | CSCH-Guided | VMs=18 | Vars=8320 | Cons=148581 | 0.005s\n",
      "✅ data_100_2 | Adaptive-GA (light) | VMs=18 | Vars=8320 | Cons=148581 | 0.138s\n",
      "✅ data_100_3 | CSCH | VMs=19 | Vars=8320 | Cons=139941 | 0.008s\n",
      "✅ data_100_3 | CSCH-Guided | VMs=19 | Vars=8320 | Cons=139941 | 0.008s\n",
      "✅ data_100_3 | Adaptive-GA (light) | VMs=19 | Vars=8320 | Cons=139941 | 0.145s\n",
      "✅ data_200_1 | CSCH | VMs=25 | Vars=16320 | Cons=543241 | 0.032s\n",
      "✅ data_200_1 | CSCH-Guided | VMs=25 | Vars=16320 | Cons=543241 | 0.032s\n",
      "✅ data_200_1 | Adaptive-GA (light) | VMs=25 | Vars=16320 | Cons=543241 | 0.551s\n",
      "✅ data_200_2 | CSCH | VMs=29 | Vars=16320 | Cons=551641 | 0.041s\n",
      "✅ data_200_2 | CSCH-Guided | VMs=29 | Vars=16320 | Cons=551641 | 0.033s\n",
      "✅ data_200_2 | Adaptive-GA (light) | VMs=29 | Vars=16320 | Cons=551641 | 0.532s\n",
      "✅ data_200_3 | CSCH | VMs=29 | Vars=16320 | Cons=554121 | 0.032s\n",
      "✅ data_200_3 | CSCH-Guided | VMs=29 | Vars=16320 | Cons=554121 | 0.039s\n",
      "✅ data_200_3 | Adaptive-GA (light) | VMs=29 | Vars=16320 | Cons=554121 | 0.553s\n",
      "\n",
      "=== RESULTS: LONG FORMAT (per apps × method) ===\n",
      " apps              method  VMs_Mean  VMs_Std  Time_Mean  Time_Std  Cores_Mean\n",
      "  100 Adaptive-GA (light) 19.333333 1.527525   0.127374  0.024693    7.400000\n",
      "  100                CSCH 19.333333 1.527525   0.007824  0.001261    7.400000\n",
      "  100         CSCH-Guided 19.333333 1.527525   0.006310  0.001605    7.400000\n",
      "  200 Adaptive-GA (light) 27.666667 2.309401   0.545371  0.011716   14.833333\n",
      "  200                CSCH 27.666667 2.309401   0.034894  0.005139   14.833333\n",
      "  200         CSCH-Guided 27.666667 2.309401   0.034662  0.003574   14.833333\n",
      "\n",
      "=== RESULTS: WIDE — Average VMs (methods as columns) ===\n",
      "method  Adaptive-GA (light)       CSCH  CSCH-Guided\n",
      "apps                                               \n",
      "100               19.333333  19.333333    19.333333\n",
      "200               27.666667  27.666667    27.666667\n",
      "\n",
      "=== RESULTS: WIDE — Runtime (s, mean ± std) ===\n",
      "method Adaptive-GA (light)           CSCH    CSCH-Guided\n",
      "apps                                                    \n",
      "100          0.127 ± 0.025  0.008 ± 0.001  0.006 ± 0.002\n",
      "200          0.545 ± 0.012  0.035 ± 0.005  0.035 ± 0.004\n",
      "\n",
      "=== RESULTS: WIDE — Average Cores Used (methods as columns) ===\n",
      "method  Adaptive-GA (light)       CSCH  CSCH-Guided\n",
      "apps                                               \n",
      "100                7.400000   7.400000     7.400000\n",
      "200               14.833333  14.833333    14.833333\n",
      "\n",
      "=== RESULTS: Table-II style — Problem scale (averaged over datasets) ===\n",
      " apps  Variables  Constraints\n",
      "  100       8320       142661\n",
      "  200      16320       549668\n",
      "\n",
      "=== RESULTS: Minimal solutions (avg over data_{i=1..3}) ===\n",
      " apps   VMs  Cores\n",
      "  100 19.33   7.40\n",
      "  200 27.67  14.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp/ipykernel_23712/1197808378.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  per_ds = df.groupby([\"apps\",\"dataset\"]).apply(min_vm_per_group).reset_index()\n"
     ]
    }
   ],
   "source": [
    "all_rows=[]\n",
    "for size in (100,200):  # expand to (100,200,300,400,500,600,700,800) \n",
    "    all_rows.append(run_all_methods_capped(size))\n",
    "df_capped = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "summarize_runs(df_capped, tag=\"RESULTS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb893531",
   "metadata": {},
   "source": [
    "## Dataset Availability\n",
    "The benchmark datasets used in this project were kindly provided to us by one of the authors of *Pan et al. (2022)*.  \n",
    "As the datasets are not publicly released, we cannot include them in this repository.  \n",
    "If you are interested in accessing the data, please contact the original authors of [Pan et al. (2022)](https://doi.org/10.1109/ITSC55140.2022.9922526).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
